---
layout: post
title: Installing Influxdb and Grafana on FreeNAS
date: 2018-08-19
description: Installing Influxdb and Grafana on FreeNAS
img: grafana.png # Add image post (optional)
tags: [grafana, influxdb] # add tag
toc: true
---

# The many and various graphs of FreeNAS

{% include figure image_path="/assets/img/freenas_graphs.png" alt="The original freenas graphs." class="image-small image-right" caption="Ye Olde Freenas Graphs." %}

Out of the box, freeNAS comes with some system graphing tools. Theres the system graphs provided by the old freenas ui, the graphs in the monitoring section of the new UI, and the graphs provided by Netdata.

## The original graphs
The graphs that are provided in the original FreeNAS GUI that offer the familiar rrd-tool look and feel. My guess is that they are generated by collectd using the rrd-tool plugin. They're functional and do what they say on the tin: you can get great performance information on your CPU, memory, ZFS metrics, etc. On the negative side they are NOT sexy in the vain on Kibana or chart.js and they have a limited retention i.e they only go back a few hours.

## The new sexiness

{% include figure image_path="/assets/img/freenas_graphs2.png" alt="The spanky new freenas graphs." class="image-small image-right" caption="Ye Newy Fancy Freenas Graphs." %}

The new FreeNAS GUI ups the attractiveness stakes by replacing the RRD tool generated graphs with some slinky svg graphs, with nice period selection sliders and pastel colour pallet that would bring a tear to Steve Job's eye. They do however suffer from the same problem as the original graphs in that the graphing period is limted. There seems to be a maximum of about 10 minutes that you can go back, which, if you're a noob freeNAS administrator like me is not enough if you're trying to figure out what happens when your scheduled scrub runs.  

## Netdata

One of the best kept secrets in FreeNAS, however, is the NetData gui that, once enabled in the service menu, gives you an amazing set of graphs out of the box. Almost every conceivable metric is on offer, and it's a super tool to learn about how everything fits together. I've spent hours peering in the graphs seeing what happens to RAM if I make a pool with Dedup enabled, or watching the network traffic ebb and flow as 'The Great Move' happens for the third time... sigh.

BUT, as it comes, netdata has a bit of a drawback, and that's the retention again. It seems to only store the last 24 hours worth of metrics. This is by design although I'm not 100% sure of the reasons behind it. I think the reason for this is that the 24 hours of data seems to take about 600 Megabytes, so that would very quickly grow beyond a small SSD or flashdrive if you increased it to a month or a year.

Anyhow, messing around with the config on the freeNAS appliance is also discouraged as all bets are off when it comes to configuration files. You never know when you're going to meticulously craft the perfect configuration for your needs but have it break something in FreeNAS that you weren't aware of or, less disasterously, simply be rewritten at the next reboot. Perhaps tuning the retention time for NetData is something that folks at in the FreeNAS community would consider something worth of elevating to a GUI level parameter?

{% include figure image_path="/assets/img/freenas_netdata2.png" alt="The hot snot that is netdata." class="image-large image-centre" caption="Ye Uber Freenas Graphs: Netdata" %}

# Sending data to Graphite


{% include figure image_path="/assets/img/freenas_export_to_graphite.png" alt="Graphite writing sneakiness" class="image-small image-right" caption="Send your metrics to a safe home." %}

One last bit of FreeNAS configuration sugar that is easy to overlook is that it's VERY easy to send all the metrics collected by the collectd daemon built into the applicance to graphite writer. Tucked away in the System/Advanced menu is a field called 'Remote Graphite Server Name'.


As the name suggests, if this field is populated, metrics will be sent to the host specified using the a Graphite style http post. So an attractive solution to my above problems of metric retention is to set up a Graphite server somewhere. And this is exactly what I did. Almost.

# The wonder of Influxdb

# The missing metric - hard drive temperatures 


```bash
#!/bin/sh

# /usr/local/sbin/send_hdd_temp_to_inflush.sh

smartctl -a /dev/ada0 | grep Temp | awk '{print "DiskTemp,component=ada0 value="$10}' \
  | curl -i -XPOST 'http://influxdb.home:8086/write?db=graphite' --data-binary @-
smartctl -a /dev/ada1 | grep Temp | awk '{print "DiskTemp,component=ada1 value="$10}' \
  | curl -i -XPOST 'http://influxdb.home:8086/write?db=graphite' --data-binary @-
smartctl -a /dev/ada2 | grep Temp | awk '{print "DiskTemp,component=ada2 value="$10}' \
  | curl -i -XPOST 'http://influxdb.home:8086/write?db=graphite' --data-binary @-
smartctl -a /dev/ada3 | grep Temp | awk '{print "DiskTemp,component=ada3 value="$10}' \
  | curl -i -XPOST 'http://influxdb.home:8086/write?db=graphite' --data-binary @-
smartctl -a /dev/ada4 | grep Temp | awk '{print "DiskTemp,component=ada4 value="$10}' \
  | curl -i -XPOST 'http://influxdb.home:8086/write?db=graphite' --data-binary @-
smartctl -a /dev/ada5 | grep Temp | awk '{print "DiskTemp,component=ada5 value="$10}' \
  | curl -i -XPOST 'http://influxdb.home:8086/write?db=graphite' --data-binary @-

```
